{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SpyDrNet Example Original\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import networkx as nx\nimport spydrnet as sdn\nimport csv\nimport os\nfrom collections import deque\nfrom itertools import chain\nimport copy\n\nblackboxes = {\n    'gmii_mac_top_HD31',\n    'gmii_mac_top 1'\n}\n\nexclude_primitives = {\n    'BUFG',\n    'BUFGCTRL',\n    'BUFIO',\n    'BUFR',\n    'OBUF',\n    'ODDR',\n    'MMCME2_ADV',\n    'IBUF',\n    'IBUFDS',\n    'IDDR',\n    'IDELAYCTRL',\n    'IDELAYE2',\n    'IOBUF',\n    'BSCANE2',\n    \n    'BUFH',\n    'BUFMR',\n    'FRAME_ECCE2',\n    'GTHE2_CHANNEL',\n    'GTHE2_COMMON',\n    'IBUF',\n    'IBUFDS',\n    'IBUFDS_DIFF_OUT',\n    'IBUFDS_GTE2',\n    'ICAPE2',\n    'ISERDESE2',\n    'OBUFDS',\n    'ODELAYE2',\n    'OSERDESE2',\n    'PCIE_3_0',\n    'PLLE2_ADV',\n    'STARTUPE2'\n}\n\npower_primives = {\n    'VCC',\n    'GND'\n}\n\ncombinational_primitives = {\n    'LUT1',\n    'LUT2',\n    'LUT3',\n    'LUT4',\n    'LUT5',\n    'LUT6',\n    'LUT6_2',\n    'MUXF7',\n    'MUXF8',\n    'AND2B1L',\n    'CARRY4'\n}\n\nsequential_primitives = {\n    'FDCE': ['C'],\n    'FDPE': ['C'],\n    'FDRE': ['C'],\n    'FDSE': ['C'],\n    'RAM32M': ['WCLK'],\n    'RAM32X1S': ['WCLK'],\n    'RAMB18E1': [\"CLKARDCLK\", \"CLKBWRCLK\"],\n    'RAMB36E1': [\"CLKARDCLK\", \"CLKBWRCLK\"],\n    'SRL16E': [\"CLK\"],\n    'SRLC16E': [\"CLK\"],\n\n    'DSP48E1': ['CLK'],\n    'FDCE': ['C'],\n    'FDPE': ['C'],\n    'FDRE': ['C'],\n    'FDSE': ['C'],\n    'FIFO18E1': ['RDCLK', 'WRCLK'],\n    'FIFO36E1': ['RDCLK', 'WRCLK'],\n    'RAM128X1D': ['WCLK'],\n    'RAM128X1S': ['WCLK'],\n    'RAM16X4S': ['WCLK'],\n    'RAM32M': ['WCLK'],\n    'RAM32X1D': ['WCLK'],\n    'RAM32X1S': ['WCLK'],\n    'RAM64M': ['WCLK'],\n    'RAM64X1D': ['WCLK'],\n    'RAM64X1S': ['WCLK'],\n    'SRL16E': ['CLK'],\n    'SRLC32E': ['CLK']\n}\n\nlut_sensitivity = None\nsensitive_lut_names = None\nsensitive_luts = None\nconnectivity_graph = None\nsequential_graph = None\nfeedback_hierarchy = None\n\nnodes_to_replicate = None\nnodes_to_vote_on = None\n\ndef run():\n    print(\"Welcome\")\n    parse_lut_sensitivities()\n    parse_netlist()\n    find_sensitive_luts()\n    inclusion_report()\n    primitive_usage_report()\n    generate_sequential_graph()\n    fold_feedback()\n    print_fold_hierarchy()\n    #select_target_nodes()\n    #determine_voters()\n    #apply_tmr()\n    #export_sequential_graph_dot(sequential_graph, feedback_hierarchy)\n    \ndef parse_lut_sensitivities():\n    global lut_sensitivity\n    lut_sensitivity = dict()\n    filename = 'sensitivity_data/overall_classification.csv'\n    if os.path.isfile(filename):\n        with open(filename) as fi:\n            reader = csv.reader(fi)\n            for row in reader:\n                lut_sensitivity[row[0]] = int(row[1])\n            \ndef parse_netlist():\n    global connectivity_graph\n    sdn.parse(\"vivado_no_ptmr_2012.09syn_orig_withSEMIP.edf\")#(\"reference_switch-baseline-pblock-20180511.edf\")#(\"b13.edf\")#\n    connectivity_graph = sdn.create_connectivity_graph()\n\ndef find_sensitive_luts():\n    global sensitive_lut_names\n    global sensitive_luts\n    sensitive_lut_names = list(name for name, value in lut_sensitivity.items() if value > 0)\n    sensitive_luts = list(sdn.get_virtual_instances(sensitive_lut_names))\n    \ndef inclusion_report():\n    len_total = len(sensitive_lut_names)\n    len_included = len(sensitive_luts)\n    if len_total > 0:\n        print(\"There are {} sensitive luts identified through fault injection.\".format(len_total))\n        print(\"There are {} included in the netlist ({:.02f}%).\".format(len_included, len_included/len_total*100))\n    \ndef primitive_usage_report():\n    prim_library = sdn.current_netlist().get_library('hdi_primitives')\n    for definition in sorted(prim_library.definitions, key=lambda x: x['EDIF.identifier']):\n        print(\"{} {}\".format(definition['EDIF.identifier'], len(definition.virtual_instances)))\n    for library in (x for x in sdn.current_netlist().libraries if x['EDIF.identifier'] != 'hdi_primitives'):\n        for definition in (x for x in library.definitions if x.is_leaf()):\n            print(\"{} {}\".format(definition['EDIF.identifier'], len(definition.virtual_instances)))\n        \ndef generate_sequential_graph():\n    global sequential_graph\n    sequential_graph = connectivity_graph.copy()\n    nodes = list(sequential_graph.nodes)\n    for node in nodes:\n        if isinstance(node, sdn.VirtualInstance) and node.instance.definition['EDIF.identifier'] not in sequential_primitives:\n            for predecessor in sequential_graph.predecessors(node):\n                for successor in sequential_graph.successors(node):\n                    sequential_graph.add_edge(predecessor, successor)\n            sequential_graph.remove_node(node)\n       \ndef fold_feedback():\n    global feedback_hierarchy\n    if os.path.isfile('feedback_hierarchy_report.txt'):\n        sets_stack = [set()]\n        quick_name_lookup = dict()\n        for vi in sdn.get_virtual_instances(hierarchical=True):\n            quick_name_lookup[vi.get_hierarchical_name()] = vi\n        with open('feedback_hierarchy_report.txt') as fi:\n            cur_level = 0\n            for line_number, line in enumerate(fi,1):\n                parts = line.strip().split(' ')\n                level = int(parts[0])\n                name = parts[1]\n                while level < cur_level:\n                    top_set = sets_stack.pop()\n                    sets_stack[-1].add(frozenset(top_set))\n                    cur_level -= 1\n                if name == \"Feedback_node\":\n                    cur_level += 1\n                    sets_stack.append(set())\n                else:\n                    vi = quick_name_lookup[name]\n                    sets_stack[-1].add(vi)\n            top_set = sets_stack.pop()\n            feedback_hierarchy = frozenset(top_set)\n    else:\n        feedback_hierarchy = _fold_feedback()\n\n\ndef _fold_feedback():\n    folded_graph = sequential_graph.copy()\n    for scc in sorted(nx.strongly_connected_components(sequential_graph), key=len, reverse=True):\n        if len(scc) == 1 and not any(ss in sequential_graph.successors(ss) for ss in scc):\n            print(\"Feed forward node\")\n            continue\n        print(\"Found SCC size {}.\".format(len(scc)))\n        \n        #Handle self loops\n        selfloop_nodes = list(x for x in scc if x in sequential_graph.successors(x))\n        number_of_selfloop_nodes = 0\n        for node in selfloop_nodes:\n            number_of_selfloop_nodes += 1\n            group = frozenset((node,))\n            successors = list(x for x in folded_graph.successors(node) if x is not node)\n            predecessors = list(x for x in folded_graph.predecessors(node) if x is not node)\n            for successor in successors:\n                folded_graph.add_edge(group, successor)\n            for predecessor in predecessors:\n                folded_graph.add_edge(predecessor, group)\n            folded_graph.remove_node(node)\n            scc.remove(node)\n            scc.add(group)\n        print(\"SCC has {} nodes with selfloops.\".format(number_of_selfloop_nodes))\n        \n        while len(scc) > 1:\n            #find nodes with minimum return distance\n            minimum_return_distances = dict()\n            min_return_distance = 2\n            still_looking = True\n            while still_looking:\n                for node in scc:\n                    # find minimum return distance\n                    found_nodes = {node}\n                    search_queue = deque()\n                    search_queue.append((node,0))\n                    while search_queue:\n                        item, depth = search_queue.popleft()\n                        if depth < min_return_distance:\n                            next_depth = depth + 1\n                            for successor in folded_graph.successors(item):\n                                if successor is node:\n                                    still_looking = False\n                                    min_return_distance = next_depth\n                                    minimum_return_distances[node] = next_depth\n                                else:\n                                    search_queue.append((successor,next_depth))\n                if still_looking:\n                    min_return_distance *= 2\n            print(\"Minimum return distance {}.\".format(min_return_distance))\n            nodes_of_return_distance = set(node for node, distance in minimum_return_distances.items() if distance == min_return_distance)\n            print(\"There are {} nodes with this return distance, {} total.\".format(len(nodes_of_return_distance), folded_graph.number_of_nodes()))\n            \n            # find tightfeedback groups\n            node_to_set = dict()\n            search_set = set(nodes_of_return_distance)\n            while search_set:\n                node = search_set.pop()\n                nearby = surround(folded_graph, node, min_return_distance-1)\n                filtered = list(x for x in nearby if x in nodes_of_return_distance)\n                print(\"This many nearby nodes {}.\".format(len(filtered)))\n                containing_scc = next(nx.strongly_connected_components(folded_graph.subgraph(filtered)))\n                search_set -= containing_scc\n                node_set = set()\n                for scc_node in containing_scc:\n                    if scc_node in node_to_set:\n                        node_set |= node_to_set[scc_node]\n                    else:\n                        node_set.add(scc_node)\n                for node_set_node in node_set:\n                    node_to_set[node_set_node] = node_set\n            print(\"Nodes after set sort {}.\".format(len(node_to_set)))\n            \n            groups = list()\n            group_ids = set()\n            for group in node_to_set.values():\n                group_id = id(group)\n                if group_id not in group_ids:\n                    group_ids.add(group_id)\n                    groups.append(frozenset(group))\n            print(\"There are {} groups.\".format(len(groups)))\n            \n            for group in groups:\n                scc -= group\n                scc.add(group)\n                predecessors = set()\n                successors = set()\n                for node in group:\n                    for predecessor in folded_graph.predecessors(node):\n                        if predecessor not in group:\n                            predecessors.add(predecessor)\n                    for successor in folded_graph.successors(node):\n                        if successor not in group:\n                            successors.add(successor)\n                assert (len(successors) + len(predecessors)) > 0\n                for predecessor in predecessors:\n                    folded_graph.add_edge(predecessor, group)\n                for successor in successors:\n                    folded_graph.add_edge(group, successor)\n                folded_graph.remove_nodes_from(group)\n    print(\"final number of nodes {}.\".format(folded_graph.number_of_nodes()))\n    return frozenset(folded_graph.nodes)\n    \nfrom collections import deque\ndef surround(graph, node, depth):\n    found_nodes = {node}\n    search_queue = deque()\n    search_queue.append((node, 0))\n    while search_queue:\n        cur_node, cur_depth = search_queue.popleft()\n        if cur_depth < depth:\n            for successor in graph.successors(cur_node):\n                if successor not in found_nodes:\n                    found_nodes.add(successor)\n                    search_queue.append((successor, cur_depth + 1))\n    return found_nodes\n\ndef print_fold_hierarchy():\n    #print_fold_hierarchy_recursive(feedback_hierarchy.nodes)\n    print_fold_hierarchy_non_recursive(feedback_hierarchy)\n\ndef print_fold_hierarchy_recursive(nodes, prefix = 0):\n    for node in sorted((x for x in nodes if not isinstance(x,sdn.VirtualPort)), key= lambda y: len(y) if isinstance(y, frozenset) else 0, reverse=True):\n        if isinstance(node, frozenset):\n            print(\"{} Feedback_node\".format(prefix))\n            print_fold_hierarchy_recursive(node, prefix = prefix + 1)\n        else:\n            print(str(prefix) + \" \" + node.get_hierarchical_name())\n\ndef print_fold_hierarchy_non_recursive(nodes):\n    with open(\"feedback_hierarchy_report.txt\", 'w') as fi:\n        depths = dict()\n        depth = 0\n        found_nodes = set(nodes)\n        search_stack = list(map(lambda node: (node, 0), sorted((x for x in found_nodes if not isinstance(x,sdn.VirtualPort)), key=lambda y: len(y) if isinstance(y, frozenset) else 0)))\n        while search_stack:\n            node, level = search_stack.pop()\n            if isinstance(node, frozenset):\n                fi.write(\"{} Feedback_node\\n\".format(level))\n                for subnode in sorted((x for x in node if not isinstance(x,sdn.VirtualPort)), key=lambda y: len(y) if isinstance(y, frozenset) else 0):\n                    search_stack.append((subnode, level+1))\n            else:\n                fi.write(\"{} {}\\n\".format(level, node.get_hierarchical_name()))\n\ndef select_target_nodes():\n    global nodes_to_replicate\n    cm, crm, parents = sort_combinational_members()\n    luts_in_feedback = list(x for x in sensitive_luts if x in crm)\n    print(\"Sensitive luts in feedback {} of {} known sensitive_luts\".format(len(luts_in_feedback), len(sensitive_luts)))\n    fbgs_with_sensitive_luts = set()\n    for lut in luts_in_feedback:\n        fbgs_with_sensitive_luts |= crm[lut]\n    print(\"There are {} feedback groups that contain sensitive luts.\".format(len(fbgs_with_sensitive_luts)))\n    selfcontained = set(x for x in fbgs_with_sensitive_luts if all(not isinstance(y, frozenset) for y in x))\n    print(\"There are {} self contained feedback groups (meaning they themselves do not contain more feedback groups).\".format(len(selfcontained)))\n    selfcontained_nodes = set()\n    for s in selfcontained:\n        selfcontained_nodes |= s\n    drive = nodes_that_drive_nodes(connectivity_graph, selfcontained_nodes)\n    driven = nodes_driven_by_nodes(connectivity_graph, selfcontained_nodes)\n    combinational_nodes = drive & driven\n    print(\"Selected {} sequential_nodes and {} combinational_nodes.\".format(len(selfcontained_nodes), len(combinational_nodes)))\n    #extend selection to include all carry_chain members:\n    carry_chain_nodes = set(x for x in combinational_nodes if x.instance.definition['EDIF.identifier'] == \"CARRY4\")\n    print(\"Carry chain nodes before extension {}.\".format(len(carry_chain_nodes)))\n    search_stack = list(carry_chain_nodes)\n    others = set()\n    while search_stack:\n        top_node = search_stack.pop()\n        for adjacent in chain(connectivity_graph.predecessors(top_node), connectivity_graph.successors(top_node)):\n            if isinstance(adjacent, sdn.VirtualInstance):\n                def_name = adjacent.instance.definition['EDIF.identifier']\n                if def_name == \"CARRY4\":\n                    if adjacent not in carry_chain_nodes:\n                        carry_chain_nodes.add(adjacent)\n                        search_stack.append(adjacent)\n                elif def_name in (sequential_primitives | combinational_primitives):\n                    others.add(adjacent)\n    print(\"Carry chain nodes after extension {}.\".format(len(carry_chain_nodes)))\n    combinational_nodes |= carry_chain_nodes\n    overall = selfcontained_nodes | combinational_nodes | others\n    drive = nodes_that_drive_nodes(connectivity_graph, overall)\n    driven = nodes_driven_by_nodes(connectivity_graph, overall)\n    overall |= drive & driven\n    print(\"Overall selection {} nodes.\".format(len(overall)))\n    nodes_to_replicate = overall\n    \ndef expand_carry_chain_selection(selection):\n    carry_chain_nodes = set(x for x in selection if x.instance.definition['EDIF.identifier'] == \"CARRY4\")\n    print(\"Carry chain nodes before extension {}.\".format(len(carry_chain_nodes)))\n    search_stack = list(carry_chain_nodes)\n    others = set()\n    while search_stack:\n        top_node = search_stack.pop()\n        for adjacent in chain(connectivity_graph.predecessors(top_node), connectivity_graph.successors(top_node)):\n            if isinstance(adjacent, sdn.VirtualInstance):\n                def_name = adjacent.instance.definition['EDIF.identifier']\n                if def_name == \"CARRY4\":\n                    if adjacent not in carry_chain_nodes:\n                        carry_chain_nodes.add(adjacent)\n                        search_stack.append(adjacent)\n                elif def_name in (sequential_primitives | combinational_primitives):\n                    others.add(adjacent)\n    print(\"Carry chain nodes after extension {}.\".format(len(carry_chain_nodes)))\n    return (carry_chain_nodes | others)\n    \ndef determine_voters_backup():\n    global nodes_to_vote_on\n    complete = set()\n    partial = set()\n    search_stack = list(nodes_to_replicate)\n    while search_stack:\n        top_node = search_stack.pop()\n        check = list(x not in nodes_to_replicate for x in connectivity_graph.successors(top_node))\n        if all(check):\n            complete.add(top_node)\n        elif any(check):\n            partial.add(top_node)\n    print(\"Reduction Voters needed complete {} partial {}.\".format(len(complete), len(partial)))\n    nodes_to_vote_on = complete | partial\n    subgraph = connectivity_graph.subgraph(nodes_to_replicate).copy()\n    subgraph.remove_nodes_from(complete)\n    subgraph.remove_nodes_from(partial)\n    containing_feedback_nodes = dict()\n    search_stack = list(feedback_hierarchy)\n    while search_stack:\n        top_node = search_stack.pop()\n        if isinstance(top_node, frozenset):\n            for node in top_node:\n                if isinstance(node, frozenset):\n                    search_stack.append(node)\n                else:\n                    containing_feedback_nodes[node] = top_node\n    looking_for_feedback = True\n    is_first_cut = True\n    while looking_for_feedback:\n        found_scc = False\n        sequential_elements_in_sccs = set()\n        for scc in (x for x in nx.strongly_connected_components(subgraph) if len(x) > 1 or any(xx in subgraph.successors(xx) for xx in x)):\n            found_scc = True\n            sequential_elements_in_sccs |= set(x for x in scc if x.instance.definition['EDIF.identifier'] in sequential_primitives)\n        print(\"sequential Nodes {}.\".format(len(sequential_elements_in_sccs)))\n        looking_for_feedback = found_scc\n        \n        if is_first_cut:\n            is_first_cut = False\n            tightfeedback = set(x for x in sequential_elements_in_sccs if len(containing_feedback_nodes[x]) == 1)\n            print(\"this many nodes in tightfeedback {}.\".format(len(tightfeedback)))\n            subgraph.remove_nodes_from(tightfeedback)\n            nodes_to_vote_on |= tightfeedback\n        elif found_scc:\n            assert False, \"Unable to break up feedback using simple tightfeedback approach.\"\n    print(\"If triplicate voter placed on output, then the graph having feedback = {}.\".format(looking_for_feedback))\n   \ndef determine_voters():\n    global nodes_to_vote_on\n    complete = set()\n    partial = set()\n    search_stack = list(nodes_to_replicate)\n    while search_stack:\n        top_node = search_stack.pop()\n        check = list(x not in nodes_to_replicate for x in connectivity_graph.successors(top_node))\n        if all(check):\n            complete.add(top_node)\n        elif any(check):\n            partial.add(top_node)\n    print(\"Reduction Voters needed complete {} partial {}.\".format(len(complete), len(partial)))\n    nodes_to_vote_on = complete | partial\n    subgraph = connectivity_graph.subgraph(nodes_to_replicate).copy()\n    subgraph.remove_nodes_from(complete)\n    subgraph.remove_nodes_from(partial)\n    looking_for_feedback = True\n    is_first_cut = True\n    while looking_for_feedback:\n        found_scc = False\n        sequential_elements_in_sccs = set()\n        for scc in (x for x in nx.strongly_connected_components(subgraph) if len(x) > 1 or any(xx in subgraph.successors(xx) for xx in x)):\n            found_scc = True\n            sequential_elements_in_sccs |= set(x for x in scc if x.instance.definition['EDIF.identifier'].startswith(\"FD\"))\n        print(\"sequential Nodes {}.\".format(len(sequential_elements_in_sccs)))\n        looking_for_feedback = found_scc\n        if sequential_elements_in_sccs:\n            highest_fanout = max(sequential_elements_in_sccs, key=lambda x: connectivity_graph.out_degree(x))\n            nodes_to_vote_on.add(highest_fanout)\n            subgraph.remove_node(highest_fanout)\n        #if is_first_cut:\n        #    is_first_cut = False\n        #    tightfeedback = set(x for x in sequential_elements_in_sccs if x in nodes_with_selfloops)\n        #    print(\"this many nodes in tightfeedback {}.\".format(len(tightfeedback)))\n        #    subgraph.remove_nodes_from(tightfeedback)\n        #    nodes_to_vote_on |= tightfeedback\n        #elif found_scc:\n        #    assert False, \"Unable to break up feedback using simple tightfeedback approach.\"\n    print(\"If triplicate voter placed on output, then the graph having feedback = {}.\".format(looking_for_feedback))   \n\ndef sort_combinational_members():\n    parents = dict()\n    combinational_mapping = dict()\n    frozenset_mappings = dict()\n    frozenset_count = 0\n    found_nodes = set()\n    search_stack = list()\n    for node in feedback_hierarchy:\n        found_nodes.add(node)\n        search_stack.append((node,False))\n    while search_stack:\n        node, visited = search_stack.pop()\n        if visited:\n            if isinstance(node, frozenset):\n                frozensets = set()\n                from_frozen_sets = set()\n                other = set()\n                for subnode in node:\n                    if isinstance(subnode, frozenset):\n                        frozensets.add(subnode)\n                        from_frozen_sets |= frozenset_mappings[subnode]\n                    else:\n                        other.add(subnode)\n                all_nodes = other | from_frozen_sets\n                drive = nodes_that_drive_nodes(connectivity_graph, all_nodes)\n                driven = nodes_driven_by_nodes(connectivity_graph, all_nodes)\n                both = drive & driven\n                combinational = both - all_nodes\n                all_nodes |= combinational\n                for member in frozensets:\n                    del frozenset_mappings[member]\n                frozenset_mappings[node] = all_nodes\n                combinational_mapping[node] = combinational\n                print(\"Completed {} so far.\".format(len(combinational_mapping)))\n        else:\n            search_stack.append((node,True))\n            if isinstance(node, frozenset):\n                for subnode in node:\n                    if subnode not in found_nodes:\n                        parents[subnode] = node\n                        found_nodes.add(subnode)\n                        search_stack.append((subnode, False))\n        combinational_reverse_mapping = dict()\n        for feedback_group, comb in combinational_mapping.items():\n            for item in comb:\n                if item not in combinational_reverse_mapping:\n                    combinational_reverse_mapping[item] = set()\n                combinational_reverse_mapping[item].add(feedback_group)\n    return combinational_mapping, combinational_reverse_mapping, parents\n    \ndef nodes_driven_by_nodes(graph, nodes):\n    driven = set()\n    for node in nodes:\n        search_stack = [node]\n        while search_stack:\n            current_node = search_stack.pop()\n            for next_node in graph.successors(current_node):\n                if isinstance(next_node, sdn.VirtualInstance) and next_node not in driven and \\\n                    next_node.instance.definition['EDIF.identifier'] in combinational_primitives:\n                    search_stack.append(next_node)\n                    driven.add(next_node)\n    return driven\n\ndef nodes_that_drive_nodes(graph, nodes):\n    drive = set()\n    for node in nodes:\n        search_stack = [node]\n        while search_stack:\n            current_node = search_stack.pop()\n            for next_node in graph.predecessors(current_node):\n                if isinstance(next_node, sdn.VirtualInstance) and next_node not in drive and \\\n                    next_node.instance.definition['EDIF.identifier'] in combinational_primitives:\n                    search_stack.append(next_node)\n                    drive.add(next_node)\n    return drive\n                \n\ndef export_sequential_graph_dot(sequential_graph, folded_graph = None, exclude_ports=True):\n    if not folded_graph:\n        folded_graph = sequential_graph\n    if exclude_ports:\n        sequential_graph = sequential_graph.subgraph(x for x in sequential_graph.nodes if isinstance(x,sdn.VirtualInstance))\n    nodeToIndex = dict()\n    for index,node in enumerate(sequential_graph.nodes):\n        nodeToIndex[node] = index\n    subgraph_index = 0\n    with open(\"sequential_graph.dot\",'w') as fi:\n        fi.write(\"digraph {\\n\")\n        fi.write(\"  rankdir=LR;\\n\")\n        if not exclude_ports:\n            fi.write(\"  subgraph cluster_{}{{\\n\".format(subgraph_index))\n            subgraph_index += 1\n            fi.write('    label=\"INPUT PORTS\";\\n')\n            for node in [x for x in sequential_graph.nodes if isinstance(x, sdn.VirtualPort) and x.port.direction == sdn.IN]:\n                label = \"{}\".format(node.get_name())\n                fi.write('  {}[label=\"{}\"];\\n'.format(nodeToIndex[node],label))\n            fi.write(\"  }\\n\")\n        subgraph_index = gen_cluster_hierarchy(fi, folded_graph.nodes, nodeToIndex, cluster_index=subgraph_index)\n        subgraph_index += 1\n        if not exclude_ports:\n            fi.write(\"  subgraph cluster_{}{{\\n\".format(subgraph_index))\n            subgraph_index += 1\n            fi.write('    label=\"OUTPUT PORTS\";\\n')\n            for node in [x for x in sequential_graph.nodes if isinstance(x, sdn.VirtualPort) and x.port.direction == sdn.OUT]:\n                label = \"{}\".format(node.get_name())\n                fi.write('  {}[label=\"{}\"];\\n'.format(nodeToIndex[node],label))\n            fi.write(\"  }\\n\")\n        for node in [x for x in sequential_graph.nodes if not isinstance(x, sdn.VirtualPort) or x.port['EDIF.identifier'] not in [\"clock\", \"reset\"]]:\n            for successor in sequential_graph.successors(node):\n                fi.write('  {} -> {};\\n'.format(nodeToIndex[node], nodeToIndex[successor]))\n        fi.write(\"}\\n\")\n\ndef gen_cluster_hierarchy(fi, nodes, nodeToIndex, prefix = \"  \", cluster_index = 0):\n    fi.write(\"{}subgraph cluster_{}{{\\n\".format(prefix, cluster_index))\n    fi.write('    label=\"FEEDBACK_GROUP\";\\n')\n    for node in sorted((x for x in nodes if not isinstance(x,sdn.VirtualPort)), key= lambda y: len(y) if isinstance(y, frozenset) else 0, reverse=True):\n        if isinstance(node, frozenset):\n            cluster_index += 1\n            cluster_index = gen_cluster_hierarchy(fi, node, nodeToIndex, prefix = \"  \" + prefix, cluster_index= cluster_index)\n        else:\n            fi.write('{}  {}[label=\"{}\"];\\n'.format(prefix,nodeToIndex[node],node.get_name()))\n    fi.write(prefix + \"}\\n\")\n    return cluster_index\n    \ndef expand(group, open_feedback=False):\n    seen = set()\n    search_stack = [group]\n    while search_stack:\n        items = search_stack.pop()\n        for item in items:\n            if isinstance(item, frozenset):\n                if item not in seen and open_feedback:\n                    seen.add(item)\n                    search_stack.append(item)\n            else:\n                yield item\n            \ndef apply_tmr():\n    triplicate_inst_map = triplicate_instances(nodes_to_replicate, uniquify_properties=[\"SOFT_LUTNM\"])\n    triplicate_port_map = triplicate_ports(based_on=nodes_to_replicate)\n    triplicate_and_connect_cables(instances=triplicate_inst_map, ports=triplicate_port_map)\n    insert_voters(on=nodes_to_vote_on, instances=triplicate_inst_map, ports=triplicate_port_map)\n    \ndef triplicate_instances(nodes_to_triplicate, uniquify_properties=None):\n    return replicate_instances(nodes_to_triplicate, suffix=\"_TMR_\", count=3, uniquify_properties=uniquify_properties)\n    \ndef replicate_instances(nodes_to_replicate, suffix=\"_COPY_\", count=2, uniquify_properties=None):\n    assert all(len(x.instance.parent_definition.virtual_instances) == 1 for x in nodes_to_replicate)\n    for node in nodes_to_replicate:\n        instance = node.instance\n        parent_definition = instance.parent_definition\n        new_instances = list()\n        for ii in range(1,count):\n            new_instance = sdn.Instance()\n            new_instance.parent_definition = parent_definition\n            for property in instance:\n                new_instance[property] = copy.deepcopy(instance[property])\n            # rename\n            new_suffix = suffix + str(ii)\n            if 'EDIF.identifier' in new_instance:\n                new_instance['EDIF.identifier'] = new_instance['EDIF.identifier'] + new_suffix\n            if 'EDIF.original_identifier' in new_instance:\n                new_instance['EDIF.original_identifier'] = new_instance['EDIF.original_identifier'] + new_suffix\n            print(new_instance['EDIF.identifier'])\n            new_instances.append(new_instance)\n            parent_definition.add_instance(new_instance)\n        break\n            \n    \ndef triplicate_ports(based_on=None):\n    return replicate_ports(based_on=based_on, suffix=\"_TMR_\", count=3)\n    \ndef replicate_ports(top_level_ports=None, based_on=None, suffix=\"_COPY_\", count=2):\n    driven_pins = set()\n    drive_pins = set()\n    if top_level_ports:\n        for tlp in top_level_ports:\n            if port.direction in {sdn.OUT, sdn.INOUT}:\n                driven_pins |= set(port.virtualPins.values())\n            if port.direction in {sdn.IN, sdn.INOUT}:\n                drive_pins |= set(port.virtualPins.values())\n    if based_on:\n        for node in based_on:\n            for port in node.virtualPorts.values():\n                if port.direction in {sdn.IN, sdn.INOUT}:\n                    driven_pins |= set(port.virtualPins.values())\n                if port.direction in {sdn.OUT, sdn.INOUT}:\n                    drive_pins |= set(port.virtualPins.values())\n    drive_wires = set(sdn.get_virtual_wires(of=driven_pins, selection=sdn.ALL))\n    driven_wires = set(sdn.get_virtual_wires(of=drive_pins, selection=sdn.ALL))\n    common_wires = drive_wires | driven_wires\n    print(\"This many wires need replicated {}.\".format(len(common_wires)))\n    virtual_pins = set()\n    for wire in common_wires:\n        virtual_pins |= set(wire.get_virtualPins())\n    virtual_ports = set()\n    for vpi in virtual_pins:\n        vpo = vpi.virtualParent\n        vi = vpo.virtualParent\n        if not vi.is_leaf():\n            virtual_ports.add(vpo)\n        else:\n            if vi.virtualParent is None:\n                assert top_level_ports and vpo in top_level_ports\n                virtual_ports.add(vpo)\n    print(\"This many ports need replicated {}.\".format(len(virtual_ports)))\n    if top_level_ports:\n        for tlp in top_level_ports:\n            virtualPorts.add(tlp)\n    for port in virtual_ports:\n        if len(port.virtualParent.instance.definition.virtual_instances) > 1:\n            assert False, \"Parent_definition_of_ports_not_unique\"\n    \ndef triplicate_and_connect_cables(instances=None, ports=None):\n    return replicate_and_connect_cables(instances=instances, ports=ports, suffix=\"_TMR_\", count=3)\n    \ndef replicate_and_connect_cables(instances=None, ports=None, suffix=\"_COPY_\", count=2):\n    pass\n    \ndef insert_voters(on=None, instances=None, ports=None):\n    pass\n\nrun()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
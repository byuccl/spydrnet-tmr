{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Decompose\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import spydrnet as sdn\nimport networkx as nx\nfrom collections import deque\n\nconnectivity_graph = None\nsequential_graph = None\nfeedback_hierarchy = None\n\ndef run():\n    global connectivity_graph\n    print(\"Welcome\")\n    netlist = sdn.parse(\"b13.edf\")\n    report_primitive_usage()\n    create_connectivity_graph()\n    create_sequential_graph()\n    fold_feedback()\n    export_sequential_graph_dot()\n    print(\"Complete\")\n    \ndef report_primitive_usage():\n    primitive_usage = dict()\n    search_stack = [sdn.current_netlist().top_instance]\n    while search_stack:\n        current_instance = search_stack.pop()\n        reference_def = current_instance.definition\n        if len(reference_def.instances) == 0 and len(reference_def.cables) == 0:\n            ref_name = reference_def['EDIF.identifier']\n            primitive_usage[ref_name] = primitive_usage.get(ref_name, 0) + 1\n        else:\n            search_stack += reference_def.instances\n    for name, count in sorted(primitive_usage.items(), key=lambda item: item[0]):\n        print(name, count)\n        \ndef create_connectivity_graph():\n    global connectivity_graph\n    connectivity_graph = sdn.create_connectivity_graph()\n    \ndef create_sequential_graph():\n    global sequential_graph\n    sequential_graph = connectivity_graph.copy()\n    nodes = list(sequential_graph.nodes)\n    for node in nodes:\n        if isinstance(node, sdn.VirtualInstance) and node.instance.definition['EDIF.identifier'].startswith(\"FD\") is False:\n            predecessors = list(sequential_graph.predecessors(node))\n            successors = list(sequential_graph.successors(node))\n            for predecessor in predecessors:\n                for successor in successors:\n                    sequential_graph.add_edge(predecessor, successor)\n            sequential_graph.remove_node(node)\n    print(\"Nodes in connectivity graph:\", connectivity_graph.number_of_nodes())\n    print(\"Nodes in sequential graph:\", sequential_graph.number_of_nodes())\n    \ndef fold_feedback():\n    global feedback_hierarchy\n    feedback_hierarchy = set()\n    # find all SCCs\n    for scc in nx.strongly_connected_components(sequential_graph):\n        if scc_has_feedback(scc) is False:\n            feedback_hierarchy |= scc\n            continue\n        print(\"Found SCC with feedback\", len(scc))\n        feedback_finder = FeedbackFinder.from_graph_and_subset(sequential_graph, scc)\n        scc_hierarchy = feedback_finder.find()\n        feedback_hierarchy.add(scc_hierarchy)\n    print(feedback_hierarchy)\n        \ndef scc_has_feedback(scc):\n    return len(scc) > 1 or all(x in sequential_graph.successors(x) for x in scc)\n    \n    \nclass FeedbackFinder:\n    @staticmethod\n    def from_graph_and_subset(graph, subset):\n        feedback_finder = FeedbackFinder()\n        feedback_finder.graph = graph.subgraph(subset).copy()\n        return feedback_finder\n    \n    def __init__(self):\n        self.graph = None\n        self.return_distances_to_nodes = None\n        self.nodes_to_return_distance = None\n        \n    def find(self):\n        print(\"Find\")\n        self.find_return_distances()\n        new_node = None\n        while self.return_distances_to_nodes:\n            min_return_distance = min(self.return_distances_to_nodes)\n            nodes_with_min_return_distance = self.return_distances_to_nodes[min_return_distance]\n            print(\"Return Distance:\", min_return_distance, \"Count:\", len(nodes_with_min_return_distance))\n            for node in nodes_with_min_return_distance:\n                print(\" \",node)\n                del self.nodes_to_return_distance[node]\n            del self.return_distances_to_nodes[min_return_distance]\n            if min_return_distance == 1:\n                nodes_to_update = list()\n                for node in nodes_with_min_return_distance:\n                    new_node = self.collapse_group([node])\n                    nodes_to_update.append(new_node)\n                self.update_return_distances(nodes_to_update)\n            else:\n                subgraph = self.graph.subgraph(nodes_with_min_return_distance)\n                sccs = list(nx.strongly_connected_components(subgraph))\n                nodes_to_update = list()\n                for scc in sccs:\n                    assert len(scc) > 1\n                    new_node = self.collapse_group(scc)\n                    nodes_to_update.append(new_node)\n                self.update_return_distances(nodes_to_update)\n        assert new_node\n        return new_node\n        \n    def find_return_distances(self):\n        self.return_distances_to_nodes = dict()\n        self.nodes_to_return_distance = dict()\n        for node in self.graph.nodes:\n            return_distance = self.find_return_distance(node)\n            self.nodes_to_return_distance[node] = return_distance\n            if return_distance not in self.return_distances_to_nodes:\n                self.return_distances_to_nodes[return_distance] = set()\n            self.return_distances_to_nodes[return_distance].add(node)\n    \n    def find_return_distance(self, node):\n        found = set()\n        search_queue = deque()\n        search_queue += map(lambda x: (x,1), self.graph.successors(node))\n        while search_queue:\n            current_node, depth = search_queue.popleft()\n            if current_node is node:\n                return depth\n            elif current_node not in found:\n                search_queue += map(lambda x: (x, depth+1), self.graph.successors(current_node))\n            found.add(current_node)\n        return -1\n        \n    def collapse_group(self, nodes):\n        new_node = frozenset(nodes)\n        predecessors = set()\n        successors = set()\n        for node in new_node:\n            for predecessor in self.graph.predecessors(node):\n                if predecessor not in new_node:\n                    predecessors.add(predecessor)\n            for successor in self.graph.successors(node):\n                if successor not in new_node:\n                    successors.add(successor)\n        for predecessor in predecessors:\n            self.graph.add_edge(predecessor, new_node)\n        for successor in successors:\n            self.graph.add_edge(new_node, successor)\n        self.graph.remove_nodes_from(new_node)\n        self.graph.add_node(new_node)\n        return new_node\n        \n    def update_return_distances(self, nodes):\n        for node in nodes:\n            self.update_return_distance(node)\n            \n    def update_return_distance(self, node):\n        # find return distance and nodes within that distance of the node\n        return_distance = self.find_return_distance(node)\n        if return_distance > 0:\n            # find nodes along a path with minimal distance to node\n            within_return_distance = self.get_nodes_within_return_distance(node, return_distance)\n            # update return distance if it does not exist or is larger than the found return_distance\n            original_node = node\n            for node in within_return_distance:\n                print(\" \", node, self.nodes_to_return_distance.get(node, None))\n                assert nx.shortest_path_length(self.graph, node, original_node) < return_distance, f\"{node} is not within return distance of {original_node}\"\n                if node not in self.nodes_to_return_distance:\n                    self.nodes_to_return_distance[node] = return_distance\n                    if return_distance not in self.return_distances_to_nodes:\n                        self.return_distances_to_nodes[return_distance] = set()\n                    self.return_distances_to_nodes[return_distance].add(node)\n                else:\n                    node_return_distance = self.nodes_to_return_distance[node]\n                    if node_return_distance > return_distance:\n                        self.return_distances_to_nodes[node_return_distance].remove(node)\n                        if len(self.return_distances_to_nodes[node_return_distance]) == 0:\n                            del self.return_distances_to_nodes[node_return_distance]\n                        self.nodes_to_return_distance[node] = return_distance\n                        if return_distance not in self.return_distances_to_nodes:\n                            self.return_distances_to_nodes[return_distance] = set()\n                        self.return_distances_to_nodes[return_distance].add(node)\n    \n    def get_nodes_within_return_distance(self, node, return_distance):\n        result = {node}\n        found = self.get_nearby_successors(node, return_distance)\n        search_stack = list(x for x in self.graph.predecessors(node) if x in found)\n        while search_stack:\n            item = search_stack.pop()\n            if item not in result:\n                result.add(item)\n                for predecssor in self.graph.predecessors(item):\n                    if predecssor in found and found[predecssor] < found[item]:\n                        search_stack.append(predecssor)\n        return result\n    \n    def get_nearby_successors(self, node, depth):\n        return self.surround(node, depth, self.graph.successors)\n\n    def get_nearby_predecessors(self, node, depth):\n        return self.surround(node, depth, self.graph.successors)\n\n    @staticmethod\n    def surround(node, depth, adj_func):\n        found_nodes = {node:0}\n        search_queue = deque()\n        search_queue.append((node, 0))\n        while search_queue:\n            cur_node, cur_depth = search_queue.popleft()\n            if cur_depth < depth - 1:\n                for successor in adj_func(cur_node):\n                    if successor not in found_nodes:\n                        found_nodes[successor] = cur_depth + 1\n                        search_queue.append((successor, cur_depth + 1))\n        return found_nodes\n                        \ndef export_sequential_graph_dot(exclude_ports=True):\n    global feedback_hierarchy\n    global sequential_graph\n    if not feedback_hierarchy:\n        feedback_hierarchy = set(sequential_graph.nodes())\n    if exclude_ports:\n        sequential_graph = sequential_graph.subgraph(x for x in sequential_graph.nodes if isinstance(x,sdn.VirtualInstance))\n    nodeToIndex = dict()\n    for index,node in enumerate(sequential_graph.nodes):\n        nodeToIndex[node] = index\n    subgraph_index = 0\n    with open(\"sequential_graph.dot\",'w') as fi:\n        fi.write(\"digraph {\\n\")\n        fi.write(\"  rankdir=LR;\\n\")\n        if not exclude_ports:\n            fi.write(\"  subgraph cluster_{}{{\\n\".format(subgraph_index))\n            subgraph_index += 1\n            fi.write('    label=\"INPUT PORTS\";\\n')\n            for node in [x for x in sequential_graph.nodes if isinstance(x, sdn.VirtualPort) and x.port.direction == sdn.IN]:\n                label = \"{}\".format(node.get_name())\n                fi.write('  {}[label=\"{}\"];\\n'.format(nodeToIndex[node],label))\n            fi.write(\"  }\\n\")\n        subgraph_index = gen_cluster_hierarchy(fi, feedback_hierarchy, nodeToIndex, cluster_index=subgraph_index)\n        subgraph_index += 1\n        if not exclude_ports:\n            fi.write(\"  subgraph cluster_{}{{\\n\".format(subgraph_index))\n            subgraph_index += 1\n            fi.write('    label=\"OUTPUT PORTS\";\\n')\n            for node in [x for x in sequential_graph.nodes if isinstance(x, sdn.VirtualPort) and x.port.direction == sdn.OUT]:\n                label = \"{}\".format(node.get_name())\n                fi.write('  {}[label=\"{}\"];\\n'.format(nodeToIndex[node],label))\n            fi.write(\"  }\\n\")\n        for node in [x for x in sequential_graph.nodes if not isinstance(x, sdn.VirtualPort) or x.port['EDIF.identifier'] not in [\"clock\", \"reset\"]]:\n            for successor in sequential_graph.successors(node):\n                fi.write('  {} -> {};\\n'.format(nodeToIndex[node], nodeToIndex[successor]))\n        fi.write(\"}\\n\")\n        \ndef gen_cluster_hierarchy(fi, nodes, nodeToIndex, prefix = \"  \", cluster_index = 0):\n    fi.write(\"{}subgraph cluster_{}{{\\n\".format(prefix, cluster_index))\n    fi.write('    label=\"FEEDBACK_GROUP\";\\n')\n    for node in sorted((x for x in nodes if not isinstance(x,sdn.VirtualPort)), key= lambda y: len(y) if isinstance(y, frozenset) else 0, reverse=True):\n        if isinstance(node, frozenset):\n            cluster_index += 1\n            cluster_index = gen_cluster_hierarchy(fi, node, nodeToIndex, prefix = \"  \" + prefix, cluster_index= cluster_index)\n        else:\n            fi.write('{}  {}[label=\"{}\"];\\n'.format(prefix,nodeToIndex[node],node.get_name()))\n    fi.write(prefix + \"}\\n\")\n    return cluster_index\n\nrun()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}